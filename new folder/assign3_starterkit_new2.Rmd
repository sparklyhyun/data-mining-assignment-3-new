---
title: "Cx4073 : Assignment 3"
author: "enter names of all team members"
date: "enter student ids of all team members"
output:
  html_document:
    theme: united
    highlight: tango
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

---

### Finding Market Segments in Online Retail

Import the CSV data file `assign1_RetailData.csv` for analysis, and quickly check the structure of the data.

```{r}
retailData <- read.csv("assign3_RetailData.csv", header = TRUE)
str(retailData)
```

The following table summarizes the variables in the dataset. Note the type carefully, and convert if required.

| Variable | Description | Remarks | 
| -------- | ------------------- | ------------------------------------------ |
| InvoiceNo | The serial number on the Invoice | May be different for same product and same customer. |
| StockCode | Product (item) code in the Store | Uniquely assigned to every distinct Product (item). |
| Description | Product (item) name in the Store | May be different for the same StockCode. Do check. |
| Quantity | Product Quantity in the Transaction | Will of course change with different transactions. |
| InvoiceDate | Date-Time of the Transaction | Can you use this too? Try, but it is strictly optional. |
| UnitPrice | Product Price per Unit (in Dollars) | Should be the same for the same Product. Do check. |
| CustomerID | Customer code in the Store | Same customer may make various purchases. Check carefully. |
| Country | Country of Residence of Customer | Should be the same for each individual Customer. |

Hint : Think of creating a Customer-Product matrix before you start your market segmentation. First step is deciding the elements in the matrix, and the second step if to choose the notion of distance that whould be appropriate for this case. See if you can effectively use the variables like `Quantity`, `UnitPrice`, `InvoiceDate` and `Country` in this market segmentation. Don't forget to interpret the market segments that you get!

---

**Continue with Data Exploration, creation of Customer-Product matrix, choice of Distance, various Clustering algorithms, and Interpretation. Submit this .Rmd file as your Solution : [StudentID1_StudentID2_StudentID3].Rmd, where the three StudentIDs are the Matriculation Numbers of the three students in your team. Change the filename appropriately if you have less than three members in your team.**

```{r}
#install.packages("dplyr")
```


---


#### Summary of Data
```{r}
summary(retailData)
head(retailData)
tail(retailData)
```


---


#### Data Pre-processing 
```{r}
library(dplyr)
df<-filter(retailData,Description!="[A-Z].*")
df1<-filter(df,Description!="SAMPLES")
df2<-filter(df1,Quantity>0 )
df3<-filter(df2,UnitPrice>0)
df4<-filter(df3,Description!="Manual")
df5<-filter(df4,Description!="Adjust bad debt")
df6<-filter(df5,Description!="Next Day Carriage")
df7<-filter(df6,CustomerID!="NA")
write.csv(df7,'retaildataNew2.csv')
```

Some data pre-processing has been performed to handle inconsistent data, missing values and irrelevant data. 

* The `Description` with different format was found to be inconsistent with the stock code. (e.g. Stock code 20711 - JUMBO BAG TOYS, inconsistent name - lost in space). Since there were very few of these inconsistent data, and removing them would not affect the dataset significantly, the items with inconsistent description were removed.
* Samples are not very relevant in this analysis as they are freely given out to the customers when they purchase another product, as a marketing strategy. Also, the customer's decision to buy a product depends more heavily on their need for the product, rather than what samples come with it. Therefore, the samples would not affect the customer's purchase decision significantly, thus they were excluded from the dataset. 
* Those items with negative `Qantity` or `Unit Price` were also removed as it is impossible to have a product sold for negative quantity or unit price
* Manuals are add-ons to the products the customers purchase. Therefore, it is highly correlated to the product it is tied to, therefore does not add much information to the analysis. Thus, manuals were also removed from the dataset. 
* Items with `Description` such as "Adjust bad debt" or "Next Day Carriage" were also excluded as they are not product's names and are inconsistent with the dataset.
* Items with missing `CustomerID` were also removed from the dataset, as `CustomerID` is a key feature used for clustering. 


---


#### Removing Anomalies 

Removing anomalies is important as anomalies can affect the clustering. Removing anomalies can make the clustering process more efficient. 

```{r}
barplot(df7$Quantity, col = "blue")
```

From the barplot above, there are 2 anomalies of `Quantity` > 20000. These were removed.  

```{r}
df7<-filter(df7,Quantity<20000 )
barplot(df7$Quantity, col = "blue")
```


```{r}
barplot(df7$UnitPrice, col = "blue")
```

From the barplot above, there is an anomaly of `UnitPrice` > 3000. This data point was also removed.

```{r}
df7<-filter(df7,UnitPrice<3000 )
barplot(df7$UnitPrice, col = "blue")
```


---


#### Extracting 1000 most frequent items 

```{r}
t2 <- subset(df7, select = c("StockCode"))
countt2 <- table(unlist(t2))
countt2df<-as.data.frame(countt2)
colnames(countt2df) <- c("StockCode", "Freq")

#head(countt2df)


countt2dfSort <- countt2df[rev(order(countt2df$Freq)),]
#head(countt2dfSort)

mostFreqProducts <- countt2dfSort[1:1000, "StockCode"]
#head(mostFreqProducts) 

mostFreqProductsExtracted <- df7[is.element(df7$StockCode, mostFreqProducts),]
head(mostFreqProductsExtracted) 
write.csv(mostFreqProductsExtracted,'extracted.csv')
```

Using the `StockCode`, 1000 most popular items sold were extracted. The 1000 most popular items were used as they were probably generating the most revenue for the store, and it is logical to focus the marketing efforts for these most popular items. 


```{r}
summary(mostFreqProductsExtracted)
str(mostFreqProductsExtracted)
```


---


#### Creating Customer-Product matrix

```{r}
xtabs(Quantity ~ CustomerID + StockCode, data = mostFreqProductsExtracted, addNA = TRUE, sparse = TRUE)

```


```{r}
#install.packages("mclust")
```


#### Clustering

**EM Clustering**

**K-Means Clustering**  

#### Conclusion


```{r}
clusterColumns <- subset(mostFreqProductsExtracted, select = c("StockCode", "Quantity", "CustomerID", "Country"))

#clusterColumns

summary(clusterColumns)
str(clusterColumns)
```



```{r}
library(mclust)

#emFit <- Mclust(clusterColumns)

#emFit

#summary(emFit)

#head(emFit)



# plot(emFit, what = "classification")

```



```{r}
#myPal <- c("red","blue","darkgreen","magenta","darkgrey","black")


clusterColumns$numStockCode <- as.numeric(clusterColumns$StockCode)
clusterColumns$numCountry <- as.numeric(clusterColumns$Country)

clusterColumns2 <- subset(clusterColumns, select = c("numStockCode", "Quantity", "CustomerID", "numCountry"))

# Single choice for random initial centroids
K <- 2    # Experiment with different values
#kMeansFit <- kmeans(clusterColumns2, centers = K)
#kMeansFit

#summary(kMeansFit)

# plot(mostFreqProductsExtracted, pch = 19, col = palette(myPal)[as.numeric(kMeansFit$cluster)])
```


```{r}
kMin <- 1
kMax <- 20
withinSS <- double(kMax - kMin + 1)
betweenSS <- double(kMax - kMin + 1)
for (K in kMin:kMax) {
  kMeansFit <-  kmeans(clusterColumns2, centers = K)
  withinSS[K] <- sum(kMeansFit$withinss)
  betweenSS[K] <- kMeansFit$betweenss
}
plot(kMin:kMax, betweenSS, pch=19, type="b", col="red",
     xlab = "Value of K", ylab = "Sum of Squares (Within and Between)")
points(kMin:kMax, withinSS, pch=19, type="b", col="green")
plot(kMin:kMax, withinSS, pch=19, type="b", col="green",
     xlab = "Value of K", ylab = "Sum of Squares (Within and Between)")
```

```{r}
kMin <- 1
kMax <- 5
withinSS <- double(kMax - kMin + 1)
betweenSS <- double(kMax - kMin + 1)
for (K in kMin:kMax) {
  kMeansFit <-  kmeans(clusterColumns2, centers = K)
  withinSS[K] <- sum(kMeansFit$withinss)
  betweenSS[K] <- kMeansFit$betweenss
}
plot(kMin:kMax, betweenSS, pch=19, type="b", col="red",
     xlab = "Value of K", ylab = "Sum of Squares (Within and Between)")
points(kMin:kMax, withinSS, pch=19, type="b", col="green")
plot(kMin:kMax, withinSS, pch=19, type="b", col="green",
     xlab = "Value of K", ylab = "Sum of Squares (Within and Between)")
```

```{r}
myPal <- c("red","blue","darkgreen","magenta","darkgrey","black")
K <- 2
kMeansFit <- kmeans(clusterColumns2, centers = K, nstart = 20)
kMeansFit
pairs(clusterColumns, pch = 19, cex = 0.5, 
      col = palette(myPal)[as.numeric(kMeansFit$cluster)])
# Note that the labels are stored as follows
kMeansFit$cluster
clustLabels <- kMeansFit$cluster
```

```{r}
kMeansFit$cluster
clustLabels <- kMeansFit$cluster
  
# We may extract the clusters as follows
kMeansClust1 = mostFreqProductsExtracted[clustLabels == 1,]
kMeansClust2 = mostFreqProductsExtracted[clustLabels == 2,]
```

```{r}
summary(kMeansClust1)
summary(kMeansClust2)
kMeansClust1$numStockCode<-  as.numeric(kMeansClust1$StockCode)
kMeansClust2$numStockCode<-  as.numeric(kMeansClust2$StockCode)
kMeansClust1$numCustomerID<-  as.numeric(kMeansClust1$CustomerID)
kMeansClust2$numCustomerID<-  as.numeric(kMeansClust2$CustomerID)
kMeansClust1$numQuantity<-  as.numeric(kMeansClust1$Quantity)
kMeansClust2$numQuantity<-  as.numeric(kMeansClust2$Quantity)
#kMeansClust1$numDescription <- as.numeric(kMeansClust1$Description)
kMeansClust2$numCountry <- as.numeric(kMeansClust2$Country)
kMeansClust1$numCountry <- as.numeric(kMeansClust1$Country)
#kMeansClust2$numDescription <- as.numeric(kMeansClust2$Description)
# Observe how the statistical summary differ
# Remember : Plot on same scales to compare
par(mfrow=c(2,2))
hist(kMeansClust1$numCountry,  col = "lightgreen")
hist(kMeansClust1$Quantity, col = "lightgreen")
hist(kMeansClust2$numCountry,  col = "steelblue")
hist(kMeansClust2$Quantity, col = "steelblue")
```
