---
title: "Cx4073 : Assignment 3"
author: "enter names of all team members"
date: "enter student ids of all team members"
output:
  html_document:
    theme: united
    highlight: tango
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

---

### Finding Market Segments in Online Retail

Import the CSV data file `assign1_RetailData.csv` for analysis, and quickly check the structure of the data.

```{r}
retailData <- read.csv("assign3_RetailData.csv", header = TRUE)
str(retailData)
```

The following table summarizes the variables in the dataset. Note the type carefully, and convert if required.

| Variable | Description | Remarks | 
| -------- | ------------------- | ------------------------------------------ |
| InvoiceNo | The serial number on the Invoice | May be different for same product and same customer. |
| StockCode | Product (item) code in the Store | Uniquely assigned to every distinct Product (item). |
| Description | Product (item) name in the Store | May be different for the same StockCode. Do check. |
| Quantity | Product Quantity in the Transaction | Will of course change with different transactions. |
| InvoiceDate | Date-Time of the Transaction | Can you use this too? Try, but it is strictly optional. |
| UnitPrice | Product Price per Unit (in Dollars) | Should be the same for the same Product. Do check. |
| CustomerID | Customer code in the Store | Same customer may make various purchases. Check carefully. |
| Country | Country of Residence of Customer | Should be the same for each individual Customer. |

Hint : Think of creating a Customer-Product matrix before you start your market segmentation. First step is deciding the elements in the matrix, and the second step if to choose the notion of distance that whould be appropriate for this case. See if you can effectively use the variables like `Quantity`, `UnitPrice`, `InvoiceDate` and `Country` in this market segmentation. Don't forget to interpret the market segments that you get!

---

**Continue with Data Exploration, creation of Customer-Product matrix, choice of Distance, various Clustering algorithms, and Interpretation. Submit this .Rmd file as your Solution : [StudentID1_StudentID2_StudentID3].Rmd, where the three StudentIDs are the Matriculation Numbers of the three students in your team. Change the filename appropriately if you have less than three members in your team.**

```{r}
#install.packages("dplyr")
```


---


#### Summary of Data
```{r}
summary(retailData)
head(retailData)
tail(retailData)
```


---


#### Data Pre-processing 
```{r}
library(dplyr)
df<-filter(retailData,Description!="[A-Z].*")
df1<-filter(df,Description!="SAMPLES")
df2<-filter(df1,Quantity>0 )
df3<-filter(df2,UnitPrice>0)
df4<-filter(df3,Description!="Manual")
df5<-filter(df4,Description!="Adjust bad debt")
df6<-filter(df5,Description!="Next Day Carriage")
df7<-filter(df6,CustomerID!="NA")
df7<-filter(df7,Country != "Unspecified")
# write.csv(df7,'retaildataNew2.csv')
```

Some data pre-processing has been performed to handle inconsistent data, missing values and irrelevant data. 

* The `Description` with different format was found to be inconsistent with the stock code. (e.g. Stock code 20711 - JUMBO BAG TOYS, inconsistent name - lost in space). Since there were very few of these inconsistent data, and removing them would not affect the dataset significantly, the items with inconsistent description were removed.
* Samples are not very relevant in this analysis as they are freely given out to the customers when they purchase another product, as a marketing strategy. Also, the customer's decision to buy a product depends more heavily on their need for the product, rather than what samples come with it. Therefore, the samples would not affect the customer's purchase decision significantly, thus they were excluded from the dataset. 
* Those items with negative `Qantity` or `Unit Price` were also removed as it is impossible to have a product sold for negative quantity or unit price
* Manuals are add-ons to the products the customers purchase. Therefore, it is highly correlated to the product it is tied to, therefore does not add much information to the analysis. Thus, manuals were also removed from the dataset. 
* Items with `Description` such as "Adjust bad debt" or "Next Day Carriage" were also excluded as they are not product's names and are inconsistent with the dataset.
* Items with missing `CustomerID` were also removed from the dataset, as `CustomerID` is a key feature used for clustering. 
* Items with unspecified country were also removed as country of residence is important in understanding the purchase pattern of the customers. 


---


#### Removing Anomalies 

Removing anomalies is important as anomalies can affect the clustering. Removing anomalies can make the clustering process more efficient. 

```{r}
barplot(df7$Quantity, col = "blue")
```

From the barplot above, there are 2 anomalies of `Quantity` > 20000. These were removed.  

```{r}
df7<-filter(df7,Quantity<20000 )
barplot(df7$Quantity, col = "blue")
```


```{r}
barplot(df7$UnitPrice, col = "blue")
```

From the barplot above, there is an anomaly of `UnitPrice` > 3000. This data point was also removed.

```{r}
df7<-filter(df7,UnitPrice<3000 )
barplot(df7$UnitPrice, col = "blue")
```


---


#### Extracting 1000 most frequent items 

```{r}
t2 <- subset(df7, select = c("StockCode"))
countt2 <- table(unlist(t2))
countt2df<-as.data.frame(countt2)
colnames(countt2df) <- c("StockCode", "Freq")

countt2dfSort <- countt2df[rev(order(countt2df$Freq)),]

mostFreqProducts <- countt2dfSort[1:1000, "StockCode"]

mostFreqProductsExtracted <- df7[is.element(df7$StockCode, mostFreqProducts),]
head(mostFreqProductsExtracted) 

# write.csv(mostFreqProductsExtracted,'extracted.csv')
```

Using the `StockCode`, 1000 most popular items sold were extracted. The 1000 most popular items were used as they were probably generating the most revenue for the store, and it is logical to focus the marketing efforts for these most popular items. 


---


#### Creating Customer-Product matrix

```{r}
xtabs(Quantity ~ CustomerID + StockCode, data = mostFreqProductsExtracted, addNA = TRUE, sparse = TRUE)

```


```{r}
#install.packages("mclust")
```


#### Clustering

**EM Clustering**

**K-Means Clustering**  

#### Conclusion


```{r}
clusterColumns <- subset(mostFreqProductsExtracted, select = c("StockCode", "Quantity", "CustomerID", "Country"))

summary(clusterColumns)
str(clusterColumns)
```



```{r}
#myPal <- c("red","blue","darkgreen","magenta","darkgrey","black")


clusterColumns$numStockCode <- as.numeric(clusterColumns$StockCode)
clusterColumns$numCountry <- as.numeric(clusterColumns$Country)

summary(clusterColumns)

clusterColumns2 <- subset(clusterColumns, select = c("numStockCode", "Quantity", "CustomerID", "numCountry"))

# Single choice for random initial centroids
K <- 2    # Experiment with different values
#kMeansFit <- kmeans(clusterColumns2, centers = K)
#kMeansFit

#summary(kMeansFit)

# plot(mostFreqProductsExtracted, pch = 19, col = palette(myPal)[as.numeric(kMeansFit$cluster)])
```


# with 4 columns

```{r}
kMin <- 1
kMax <- 20
withinSS <- double(kMax - kMin + 1)
betweenSS <- double(kMax - kMin + 1)
for (K in kMin:kMax) {
  kMeansFit <-  kmeans(clusterColumns2, centers = K)
  withinSS[K] <- sum(kMeansFit$withinss)
  betweenSS[K] <- kMeansFit$betweenss
}
plot(kMin:kMax, betweenSS, pch=19, type="b", col="red",
     xlab = "Value of K", ylab = "Sum of Squares (Within and Between)")
points(kMin:kMax, withinSS, pch=19, type="b", col="green")
plot(kMin:kMax, withinSS, pch=19, type="b", col="green",
     xlab = "Value of K", ylab = "Sum of Squares (Within and Between)")
```

```{r}
kMin <- 1
kMax <- 5
withinSS <- double(kMax - kMin + 1)
betweenSS <- double(kMax - kMin + 1)
for (K in kMin:kMax) {
  kMeansFit <-  kmeans(clusterColumns2, centers = K)
  withinSS[K] <- sum(kMeansFit$withinss)
  betweenSS[K] <- kMeansFit$betweenss
}
plot(kMin:kMax, betweenSS, pch=19, type="b", col="red",
     xlab = "Value of K", ylab = "Sum of Squares (Within and Between)")
points(kMin:kMax, withinSS, pch=19, type="b", col="green")
plot(kMin:kMax, withinSS, pch=19, type="b", col="green",
     xlab = "Value of K", ylab = "Sum of Squares (Within and Between)")
```

# with 2 columns each 

# stock code vs country 
```{r}
clusterColumns3 <- subset(clusterColumns, select = c("numStockCode", "numCountry"))
kMin <- 1
kMax <- 10
withinSS <- double(kMax - kMin + 1)
betweenSS <- double(kMax - kMin + 1)
for (K in kMin:kMax) {
  kMeansFit <-  kmeans(clusterColumns3, centers = K)
  withinSS[K] <- sum(kMeansFit$withinss)
  betweenSS[K] <- kMeansFit$betweenss
}
plot(kMin:kMax, betweenSS, pch=19, type="b", col="red",
     xlab = "Value of K", ylab = "Sum of Squares (Within and Between)")
points(kMin:kMax, withinSS, pch=19, type="b", col="green")
plot(kMin:kMax, withinSS, pch=19, type="b", col="green",
     xlab = "Value of K", ylab = "Sum of Squares (Within and Between)")
```

```{r}
K <- 5
kMeansFit <- kmeans(clusterColumns3, centers = K, nstart = 20)
kMeansFit

# Note that the labels are stored as follows
kMeansFit$cluster

clusterColumns3$cluster <- kMeansFit$cluster

clusterColumns3

```

# pulling apart a cluster 
```{r}

mostFreqProductsExtracted$numStockCode <- clusterColumns$numStockCode
mostFreqProductsExtracted$numCountry <- clusterColumns$numCountry
mostFreqProductsExtracted$cluster <- clusterColumns3$cluster
mostFreqProductsExtracted

#sort by cluster & write to file 

clsuterProductCountry <- mostFreqProductsExtracted[order(mostFreqProductsExtracted$cluster),]
clsuterProductCountry

# write.csv(clsuterProductCountry,'clusterProductCustomer.csv')

# separate each cluster into diff dataframe

allProductCountryClusters <- read.csv("clusterProductCustomer.csv", header = TRUE)

allProductCountryClusters

clusterLabels <- allProductCountryClusters$cluster

productCountryCluster1 <- allProductCountryClusters[clusterLabels == 1,]
productCountryCluster1
productCountryCluster2 <- allProductCountryClusters[clusterLabels == 2,]
productCountryCluster2
productCountryCluster3 <- allProductCountryClusters[clusterLabels == 3,]
productCountryCluster3
productCountryCluster4 <- allProductCountryClusters[clusterLabels == 4,]
productCountryCluster4
productCountryCluster5 <- allProductCountryClusters[clusterLabels == 5,]
productCountryCluster5

# for each product, get top 10 products

# cluster 1
#trying to get top 10
cluster1 <- subset(productCountryCluster1, select = c("StockCode"))
cluster1
clutercount1 <- table(unlist(cluster1))
clutercount1
count1<-as.data.frame(clutercount1)
colnames(count1) <- c("StockCode", "Freq")
count1

sortcluster1 <- count1[rev(order(count1$Freq)),]
sortcluster1

top10cluster1 <- sortcluster1[1:10, "StockCode"]
top10cluster1

top10cluster1extracted <- productCountryCluster1[is.element(productCountryCluster1$StockCode, top10cluster1),]
top10cluster1extracted


stockcodes1 <- unique(top10cluster1extracted$StockCode)
stockcodes1

descriptions1 <- unique(top10cluster1extracted$Description)
descriptions1

# different spacing for LUNCH BAG SUKI DESIGN 

# cluster 2
#trying to get top 10
cluster2 <- subset(productCountryCluster2, select = c("StockCode"))
clutercount2 <- table(unlist(cluster2))
count2<-as.data.frame(clutercount2)
count2
colnames(count2) <- c("StockCode", "Freq")
count2

sortcluster2 <- count2[rev(order(count2$Freq)),]
sortcluster2

top10cluster2 <- sortcluster2[1:10, "StockCode"]
top10cluster2

top10cluster2extracted <- productCountryCluster2[is.element(productCountryCluster2$StockCode, top10cluster2),]
top10cluster2extracted


stockcodes2 <- unique(top10cluster2extracted$StockCode)
stockcodes2

descriptions2 <- unique(top10cluster2extracted$Description)
descriptions2
```





# stock code vs customer 
```{r}
clusterColumns3 <- subset(clusterColumns, select = c("numStockCode", "CustomerID"))
kMin <- 1
kMax <- 10
withinSS <- double(kMax - kMin + 1)
betweenSS <- double(kMax - kMin + 1)
for (K in kMin:kMax) {
  kMeansFit <-  kmeans(clusterColumns3, centers = K)
  withinSS[K] <- sum(kMeansFit$withinss)
  betweenSS[K] <- kMeansFit$betweenss
}
plot(kMin:kMax, betweenSS, pch=19, type="b", col="red",
     xlab = "Value of K", ylab = "Sum of Squares (Within and Between)")
points(kMin:kMax, withinSS, pch=19, type="b", col="green")
plot(kMin:kMax, withinSS, pch=19, type="b", col="green",
     xlab = "Value of K", ylab = "Sum of Squares (Within and Between)")
```




```{r}
myPal <- c("red","blue","darkgreen","magenta","darkgrey","black")
K <- 2
kMeansFit <- kmeans(clusterColumns2, centers = K, nstart = 20)
kMeansFit
pairs(clusterColumns, pch = 19, cex = 0.5, 
      col = palette(myPal)[as.numeric(kMeansFit$cluster)])
# Note that the labels are stored as follows
kMeansFit$cluster
clustLabels <- kMeansFit$cluster
```

```{r}
kMeansFit$cluster
clustLabels <- kMeansFit$cluster
  
# We may extract the clusters as follows
kMeansClust1 = mostFreqProductsExtracted[clustLabels == 1,]
kMeansClust2 = mostFreqProductsExtracted[clustLabels == 2,]
```

```{r}
summary(kMeansClust1)
summary(kMeansClust2)
kMeansClust1$numStockCode<-  as.numeric(kMeansClust1$StockCode)
kMeansClust2$numStockCode<-  as.numeric(kMeansClust2$StockCode)
kMeansClust1$numCustomerID<-  as.numeric(kMeansClust1$CustomerID)
kMeansClust2$numCustomerID<-  as.numeric(kMeansClust2$CustomerID)
kMeansClust1$numQuantity<-  as.numeric(kMeansClust1$Quantity)
kMeansClust2$numQuantity<-  as.numeric(kMeansClust2$Quantity)
#kMeansClust1$numDescription <- as.numeric(kMeansClust1$Description)
kMeansClust2$numCountry <- as.numeric(kMeansClust2$Country)
kMeansClust1$numCountry <- as.numeric(kMeansClust1$Country)
#kMeansClust2$numDescription <- as.numeric(kMeansClust2$Description)
# Observe how the statistical summary differ
# Remember : Plot on same scales to compare
par(mfrow=c(2,2))
hist(kMeansClust1$numCountry,  col = "lightgreen")
hist(kMeansClust1$Quantity, col = "lightgreen")
hist(kMeansClust2$numCountry,  col = "steelblue")
hist(kMeansClust2$Quantity, col = "steelblue")
```
